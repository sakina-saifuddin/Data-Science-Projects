{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Survival Prediction Using Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt7cPMoUQxWV"
   },
   "source": [
    "Build a Na¨ıve Bayes algorithm on the titanic data set attached to predict whether a passenger survived or not.\n",
    " This data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner ”Titanic”, summarized according to survival (target variable with 1=survived and 0=died) and explanatory variables: Name, Pclass (passenger class), Sex, Age, SibSp (total number of siblings including the spouse traveling with the passenger), Parch (total number of parents and children traveling with the passenger), Ticket, Fare, Cabin, and Embarked (where the traveler mounted from: Southampton, Cherbourg, or Queenstown).\n",
    "\n",
    " ## 1. Import the data set into pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tbs0l_lyVXqQ"
   },
   "outputs": [],
   "source": [
    "# 1. Import the dataset into pandas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dM8Q3i8QJO0",
    "outputId": "1c261793-f11b-404d-a1c9-c7af430ed8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top rows of the dataset:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (change path if needed)\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(\"Top rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AatAgbkFRbOm"
   },
   "source": [
    "## 2. Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9srnhITRbrY",
    "outputId": "55e59f8b-f824-40aa-d8db-c304073aedea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (712, 7)\n",
      "Shape of X_test: (179, 7)\n",
      "Shape of y_train: (712,)\n",
      "Shape of y_test: (179,)\n"
     ]
    }
   ],
   "source": [
    "# 2. Split the data into training and test sets\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I07bsbGRvjk"
   },
   "source": [
    "## 3. Select one or more explanatory variables you would like to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktccJoLmSpue"
   },
   "source": [
    "I will use all the remaining features as explanatory variables for building the Naive Bayes model: Pclass, Sex, Age, SibSp, Parch, Fare, and Embarked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc4HK_rtSu11"
   },
   "source": [
    "## 4. Figure out if there are any missing values in the explanatory variables you want to use and either delete those passengers from the data set or fill in the missing values. If a numerical variable has missing values, you might fill those in with the average or median of that variable. If a categorical variable has missing values, you might fill those in using the most common value. You can create your own script for missing values or you can use sklearn SimpleImputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwxUfQtoWBJJ",
    "outputId": "f20b271a-b084-4916-a85e-0e2b7fe869b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train before imputation:\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         137\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "\n",
      "Missing values in X_test before imputation:\n",
      "Pclass       0\n",
      "Sex          0\n",
      "Age         40\n",
      "SibSp        0\n",
      "Parch        0\n",
      "Fare         0\n",
      "Embarked     0\n",
      "dtype: int64\n",
      "\n",
      "Shape of X_train_processed: (712, 10)\n",
      "Shape of X_test_processed: (179, 10)\n"
     ]
    }
   ],
   "source": [
    "# 4. Handle missing values (numerical -> median, categorical -> most frequent)\n",
    "print(\"Missing values in X_train before imputation:\")\n",
    "print(X_train.isnull().sum())\n",
    "print(\"\\nMissing values in X_test before imputation:\")\n",
    "print(X_test.isnull().sum())\n",
    "\n",
    "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Apply the transformations to X_train and X_test\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"\\nShape of X_train_processed:\", X_train_processed.shape)\n",
    "print(\"Shape of X_test_processed:\", X_test_processed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1Obk8etS_Sd"
   },
   "source": [
    " ## 5. Convert the categorical variables to numerical using encoding. You can create your own script or use sklearn LabelEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYUKKM89Wl8w"
   },
   "source": [
    "Done above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi6rbx3lWfHs"
   },
   "source": [
    "### This step was completed earlier using OneHotEncoder as part of the ColumnTransformer setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md-E_IclTKPu"
   },
   "source": [
    "## 6. Build a model on the training data. You can create your own code or use sklearn Na¨ıveBayes. If you use a mix of continuous and categorical explanatory variables, think of how you can build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJFnOzJyWx7K",
    "outputId": "fe0d6e23-1413-4011-c72e-4912a243094c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# 6. Build Naive Bayes model using the training data\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Naive Bayes model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mU7gjgRTP5C"
   },
   "source": [
    "## 7. Inspect the evaluation measures (accuracy score, confusion matrix, classification report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jag9_LWkXGd9",
    "outputId": "e771a4bc-3036-4a0d-a894-1bdeda6e93ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7877\n",
      "\n",
      "Confusion Matrix:\n",
      " [[93 17]\n",
      " [21 48]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       110\n",
      "           1       0.74      0.70      0.72        69\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.77      0.77       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
    "\n",
    "# Generate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Generate Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KivsgqTSBje"
   },
   "source": [
    "## 8. Take some values for the explanatory variables and use your model to predict if that person would have survived or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsLRru8wXKOx",
    "outputId": "ad533252-f3ce-4c6c-bfbe-981d89190615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample passengers:\n",
      "   Pclass     Sex  Age  SibSp  Parch    Fare Embarked\n",
      "0       1  female   30      0      0  100.00        C\n",
      "1       3    male   25      0      0    7.25        S\n",
      "2       2    male   60      1      0   20.00        Q\n",
      "\n",
      "Predicted Survival (1=survived, 0=died) for preprocessed samples:\n",
      "[1 0 0]\n",
      "\n",
      "Predicted Probabilities [P(died), P(survived)] for preprocessed samples:\n",
      "[[2.29451196e-05 9.99977055e-01]\n",
      " [9.93680084e-01 6.31991609e-03]\n",
      " [8.31802635e-01 1.68197365e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 8. Predict survival for new passengers\n",
    "\n",
    "sample_passengers = pd.DataFrame([\n",
    "    {'Pclass': 1, 'Sex': 'female', 'Age': 30, 'SibSp': 0, 'Parch': 0, 'Fare': 100, 'Embarked': 'C'},\n",
    "    {'Pclass': 3, 'Sex': 'male', 'Age': 25, 'SibSp': 0, 'Parch': 0, 'Fare': 7.25, 'Embarked': 'S'},\n",
    "    {'Pclass': 2, 'Sex': 'male', 'Age': 60, 'SibSp': 1, 'Parch': 0, 'Fare': 20, 'Embarked': 'Q'}\n",
    "])\n",
    "\n",
    "# Apply the same preprocessor to the sample passengers\n",
    "sample_passengers_processed = preprocessor.transform(sample_passengers)\n",
    "\n",
    "predictions = model.predict(sample_passengers_processed)\n",
    "probabilities = model.predict_proba(sample_passengers_processed)\n",
    "\n",
    "print(\"\\nSample passengers:\")\n",
    "print(sample_passengers)\n",
    "\n",
    "print(\"\\nPredicted Survival (1=survived, 0=died) for preprocessed samples:\")\n",
    "print(predictions)\n",
    "\n",
    "print(\"\\nPredicted Probabilities [P(died), P(survived)] for preprocessed samples:\")\n",
    "print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
